{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37590b21",
   "metadata": {},
   "source": [
    "[Github Repo](https://github.com/niconielsen32/ComputerVision/blob/master/ArUco/arucoPoseEstimation.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2d1fc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import sys\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "771b70cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARUCO_DICT = {\n",
    "\t\"DICT_4X4_50\": cv2.aruco.DICT_4X4_50,\n",
    "\t\"DICT_4X4_100\": cv2.aruco.DICT_4X4_100,\n",
    "\t\"DICT_4X4_250\": cv2.aruco.DICT_4X4_250,\n",
    "\t\"DICT_4X4_1000\": cv2.aruco.DICT_4X4_1000,\n",
    "\t\"DICT_5X5_50\": cv2.aruco.DICT_5X5_50,\n",
    "\t\"DICT_5X5_100\": cv2.aruco.DICT_5X5_100,\n",
    "\t\"DICT_5X5_250\": cv2.aruco.DICT_5X5_250,\n",
    "\t\"DICT_5X5_1000\": cv2.aruco.DICT_5X5_1000,\n",
    "\t\"DICT_6X6_50\": cv2.aruco.DICT_6X6_50,\n",
    "\t\"DICT_6X6_100\": cv2.aruco.DICT_6X6_100,\n",
    "\t\"DICT_6X6_250\": cv2.aruco.DICT_6X6_250,\n",
    "\t\"DICT_6X6_1000\": cv2.aruco.DICT_6X6_1000,\n",
    "\t\"DICT_7X7_50\": cv2.aruco.DICT_7X7_50,\n",
    "\t\"DICT_7X7_100\": cv2.aruco.DICT_7X7_100,\n",
    "\t\"DICT_7X7_250\": cv2.aruco.DICT_7X7_250,\n",
    "\t\"DICT_7X7_1000\": cv2.aruco.DICT_7X7_1000,\n",
    "\t\"DICT_ARUCO_ORIGINAL\": cv2.aruco.DICT_ARUCO_ORIGINAL,\n",
    "\t\"DICT_APRILTAG_16h5\": cv2.aruco.DICT_APRILTAG_16h5,\n",
    "\t\"DICT_APRILTAG_25h9\": cv2.aruco.DICT_APRILTAG_25h9,\n",
    "\t\"DICT_APRILTAG_36h10\": cv2.aruco.DICT_APRILTAG_36h10,\n",
    "\t\"DICT_APRILTAG_36h11\": cv2.aruco.DICT_APRILTAG_36h11\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1aba4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aruco_display(corners, ids, rejected, image):\n",
    "    \n",
    "\tif len(corners) > 0:\n",
    "\t\t\n",
    "\t\tids = ids.flatten()\n",
    "\t\t\n",
    "\t\tfor (markerCorner, markerID) in zip(corners, ids):\n",
    "\t\t\t\n",
    "\t\t\tcorners = markerCorner.reshape((4, 2))\n",
    "\t\t\t(topLeft, topRight, bottomRight, bottomLeft) = corners\n",
    "\t\t\t\n",
    "\t\t\ttopRight = (int(topRight[0]), int(topRight[1]))\n",
    "\t\t\tbottomRight = (int(bottomRight[0]), int(bottomRight[1]))\n",
    "\t\t\tbottomLeft = (int(bottomLeft[0]), int(bottomLeft[1]))\n",
    "\t\t\ttopLeft = (int(topLeft[0]), int(topLeft[1]))\n",
    "\n",
    "\t\t\tcv2.line(image, topLeft, topRight, (0, 255, 0), 2)\n",
    "\t\t\tcv2.line(image, topRight, bottomRight, (0, 255, 0), 2)\n",
    "\t\t\tcv2.line(image, bottomRight, bottomLeft, (0, 255, 0), 2)\n",
    "\t\t\tcv2.line(image, bottomLeft, topLeft, (0, 255, 0), 2)\n",
    "\t\t\t\n",
    "\t\t\tcX = int((topLeft[0] + bottomRight[0]) / 2.0)\n",
    "\t\t\tcY = int((topLeft[1] + bottomRight[1]) / 2.0)\n",
    "\t\t\tcv2.circle(image, (cX, cY), 4, (0, 0, 255), -1)\n",
    "\t\t\t\n",
    "\t\t\tcv2.putText(image, str(markerID),(topLeft[0], topLeft[1] - 10), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "\t\t\t\t0.5, (0, 255, 0), 2)\n",
    "\t\t\tprint(\"[Inference] ArUco marker ID: {}\".format(markerID))\n",
    "\t\t\t\n",
    "\treturn image\n",
    "\n",
    "\n",
    "\n",
    "def pose_estimation(frame, aruco_dict_type, matrix_coefficients, distortion_coefficients):\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    cv2.aruco_dict = cv2.aruco.Dictionary_get(aruco_dict_type)\n",
    "    parameters = cv2.aruco.DetectorParameters_create()\n",
    "\n",
    "    corners, ids, rejected_img_points = cv2.aruco.detectMarkers(gray, cv2.aruco_dict,parameters=parameters,cameraMatrix=matrix_coefficients, distCoeff=distortion_coefficients)\n",
    "        \n",
    "    if len(corners) > 0:\n",
    "        for i in range(0, len(ids)):\n",
    "           \n",
    "            rvec, tvec, markerPoints = cv2.aruco.estimatePoseSingleMarkers(corners[i], 0.02, matrix_coefficients, distortion_coefficients)\n",
    "            cv2.aruco.drawDetectedMarkers(frame, corners) \n",
    "            cv2.aruco.drawAxis(frame, matrix_coefficients, distortion_coefficients, rvec, tvec, 0.01)  \n",
    "\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15ba8ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87c0cf27",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) :-1: error: (-5:Bad argument) in function 'detectMarkers'\n> Overload resolution failed:\n>  - 'cameraMatrix' is an invalid keyword argument for detectMarkers()\n>  - 'cameraMatrix' is an invalid keyword argument for detectMarkers()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13340/2764313256.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misOpened\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpose_estimation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mARUCO_DICT\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maruco_type\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mintrinsic_camera\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdistortion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Estimated Pose'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m#     key = cv2.waitKey(1) & 0xFF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13340/250094800.py\u001b[0m in \u001b[0;36mpose_estimation\u001b[1;34m(frame, aruco_dict_type, matrix_coefficients, distortion_coefficients)\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[0mparameters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maruco\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDetectorParameters_create\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m     \u001b[0mcorners\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrejected_img_points\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maruco\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectMarkers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maruco_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcameraMatrix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmatrix_coefficients\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdistCoeff\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdistortion_coefficients\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorners\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.6.0) :-1: error: (-5:Bad argument) in function 'detectMarkers'\n> Overload resolution failed:\n>  - 'cameraMatrix' is an invalid keyword argument for detectMarkers()\n>  - 'cameraMatrix' is an invalid keyword argument for detectMarkers()\n"
     ]
    }
   ],
   "source": [
    "aruco_type = \"DICT_5X5_100\"\n",
    "arucoDict = cv2.aruco.Dictionary_get(ARUCO_DICT[aruco_type])\n",
    "arucoParams = cv2.aruco.DetectorParameters_create()\n",
    "\n",
    "intrinsic_camera = np.array(((933.15867, 0, 657.59),(0,933.1586, 400.36993),(0,0,1)))\n",
    "distortion = np.array((-0.43948,0.18514,0,0))\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, img = cap.read()\n",
    "    output = pose_estimation(img, ARUCO_DICT[aruco_type], intrinsic_camera, distortion)\n",
    "    cv2.imshow('Estimated Pose', output)\n",
    "#     key = cv2.waitKey(1) & 0xFF\n",
    "#     if key == ord('q'):\n",
    "#         break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
